{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9965b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fsspec\n",
    "import hydra\n",
    "import lightning as L\n",
    "import omegaconf\n",
    "import rich.syntax\n",
    "import rich.tree\n",
    "import torch\n",
    "import datasets\n",
    "import dataloader\n",
    "import diffusion\n",
    "import utils\n",
    "\n",
    "import json\n",
    "import mauve\n",
    "\n",
    "omegaconf.OmegaConf.register_new_resolver(\n",
    "  'cwd', os.getcwd)\n",
    "omegaconf.OmegaConf.register_new_resolver(\n",
    "  'device_count', torch.cuda.device_count)\n",
    "omegaconf.OmegaConf.register_new_resolver(\n",
    "  'eval', eval)\n",
    "omegaconf.OmegaConf.register_new_resolver(\n",
    "  'div_up', lambda x, y: (x + y - 1) // y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a160b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.environ.get('HOME')\n",
    "checkpoint_path=f\"{HOME}/Git/remdm/outputs/checkpoints/mdlm.ckpt\"\n",
    "T=0\n",
    "sampling_steps=128 #1024\n",
    "p=0.9\n",
    "num_sample_batches=1 # 5000\n",
    "global_batch_size=512\n",
    "devices=1\n",
    "generated_seqs_path=f\"{HOME}/Git/remdm/outputs/mdlm_T-{sampling_steps}_topp-{p}.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "455e5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Lucibello/.conda/envs/remdm/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs for training.\n",
      "Using 1 batch size and 1 eval batch size. Global batch size is 512.\n",
      "num_nodes: 1,        accumulate_grad_batches: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e984c304e3284cfbae6f42dc61f04334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/21 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fe602079f84fd9865b6454254471fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset00.tar:   0%|          | 0.00/633M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e8cb24f4a044379c84c8cd7e9071b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset01.tar:   0%|          | 0.00/629M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fc7cf8aa774d2ba9c8f11788bac855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset02.tar:   0%|          | 0.00/629M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35754c3baebc490e9b19c01c0143faf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset03.tar:   0%|          | 0.00/628M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5fc779a6aa40f385110afdd20a0edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset04.tar:   0%|          | 0.00/627M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505aedb0184a4a1bbd2b2ff444eafc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset05.tar:   0%|          | 0.00/630M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe1a0af15d947248244ed4b1733973d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset06.tar:   0%|          | 0.00/626M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c3daff35e4499482e03a5522cf3f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset07.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c68b26a23a0441f8eff05a7f7339107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset08.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7e0ee3a1644555b23b0b6e0e9e8820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset09.tar:   0%|          | 0.00/626M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9f6a4fff3343299726bb26f7160771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset10.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619659eb7f7049459bf39cc18493eade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset11.tar:   0%|          | 0.00/625M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1e932975124d86acbc93260ef37dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset12.tar:   0%|          | 0.00/624M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4daaa39392be4e19b0382539e7d84405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset13.tar:   0%|          | 0.00/629M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e47e3c08d94bb2bf272473a81191b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset14.tar:   0%|          | 0.00/627M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6366339026546d5bfe5599cd22f3aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset15.tar:   0%|          | 0.00/621M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31cb5a0725847119cf195b63a8fecaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset16.tar:   0%|          | 0.00/619M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab543a9b99348dbbce52a69ea8ae3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset17.tar:   0%|          | 0.00/619M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbdd5aab1f8438296ab4f0ce0820a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset18.tar:   0%|          | 0.00/618M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6e139ba00943f4b9b1652fb07f1f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset19.tar:   0%|          | 0.00/619M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1937d82e9dc44dd89c8274be02f2a7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "subsets/urlsf_subset20.tar:   0%|          | 0.00/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd1ef15c07649c99a39b948de4b5fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48215de246be40b3908dd59f0c7570dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing (num_proc=8):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3475 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1384 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1318 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0eb4a5bd1b4f579d3b1fb2cc9045e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping (num_proc=8):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a95c97960354f9eb1fbdadb07d43263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/110466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# config = omegaconf.OmegaConf.load(\"configs/config.yaml\")\n",
    "\n",
    "with hydra.initialize(config_path=\"configs/\", version_base=None):\n",
    "    config = hydra.compose(config_name=\"config\", overrides=[\n",
    "        f\"data=openwebtext-split\",\n",
    "        f\"eval.checkpoint_path={checkpoint_path}\",\n",
    "        f\"time_conditioning=false\",\n",
    "        f\"T={T}\",\n",
    "        f\"loader.global_batch_size={global_batch_size}\",\n",
    "        f\"sampling.steps={sampling_steps}\",\n",
    "        f\"seed=1\",\n",
    "        f\"loader.batch_size=1\",\n",
    "        f\"loader.eval_batch_size=1\",\n",
    "        f\"eval.perplexity_batch_size=1\",\n",
    "        f\"sampling.num_sample_batches={num_sample_batches}\",\n",
    "        f\"sampling.generated_seqs_path={generated_seqs_path}\",\n",
    "        f\"sampling.nucleus_p={p}\",\n",
    "        f\"sampling.sampler=mdlm\",\n",
    "        f\"trainer.devices={devices}\",\n",
    "        f\"data.cache_dir={HOME}/Git/remdm/outputs/data\",\n",
    "    ])\n",
    "tokenizer = dataloader.get_tokenizer(config)\n",
    "_, valid_loader = dataloader.get_dataloaders(config, tokenizer, valid_seed=config.seed, skip_train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ea95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=next(iter(valid_loader))  # warmup dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243b1c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"input_ids\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remdm",
   "language": "python",
   "name": "remdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
